services:
 
  devcontainer:
    build: 
      context: .
      dockerfile: ./Dockerfile    
    volumes:
      - ..:/workspaces/gai-ttt-svr
      - ${HOME}/.cache:/home/kakkoii1337/.cache
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    command: sleep infinity

  ollama:
    image: ollama/ollama:0.3.8
    hostname: ollama
    volumes:
      - ${HOME}/.ollama:/root/.ollama
      - ${HOME}/.cache:/root/.cache
    deploy:
        resources:
            reservations:
                devices:
                    - capabilities: [gpu]
                      driver: nvidia
                      count: all      
    ports:
      - "11434:11434"

volumes:
  ollama: