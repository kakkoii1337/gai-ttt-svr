{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Text LLM Server\n",
    "\n",
    "This repository is designed to be used with Visual Studio Code and Docker DevContainer.\n",
    "\n",
    "![dev-container](../img/dev-container.png)\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "a) Download model\n",
    "\n",
    "```bash\n",
    "huggingface-cli download bartowski/Mistral-7B-Instruct-v0.3-exl2 \\\n",
    "    --local-dir ~/.gai/models/exllamav2-mistral7b \\\n",
    "    --local-dir-use-symlinks False\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Smoke Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">5.84</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;92m5.84\u001b[0m\u001b[92m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Performance load_config                      </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 6.00 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 6.00 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">     21.46 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     21.46 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       5.88 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">     -0.00 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      5.89 GB </span>│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Performance load_config                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mChange Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m6.00 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m6.00 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m    21.46 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    21.46 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      5.88 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m    -0.00 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     5.89 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Performance load_model                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0.01 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 0.01 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.22 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.22 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       5.89 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.00 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      5.89 GB </span>│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Performance load_model                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mChange Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0.01 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m0.01 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.22 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.22 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      5.89 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.00 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     5.89 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                       Performance load_cache                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">   Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 50.15 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 50.15 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      24.42 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      24.42 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       5.89 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">       4.65 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       1.24 GB </span>│\n",
       "└───────────────────┴───────────────┴───────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                       Performance load_cache                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Change Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m  Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m50.15 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m50.15 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     24.42 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     24.42 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      5.89 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m      4.65 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      1.24 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴───────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                    Performance load_tokenizer                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 2.93 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 2.93 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">     49.62 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     49.62 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       1.23 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.01 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      1.22 GB </span>│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                    Performance load_tokenizer                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mChange Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m2.93 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m2.93 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m    49.62 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    49.62 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      1.23 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.01 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     1.22 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">1.22</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;91m1.22\u001b[0m\u001b[91m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">5.73</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;92m5.73\u001b[0m\u001b[92m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gai.lib.server.singleton_host import SingletonHost\n",
    "from gai.lib.common.utils import free_mem\n",
    "from rich.console import Console\n",
    "console=Console()\n",
    "\n",
    "config = {\n",
    "    \"type\": \"ttt\",\n",
    "    \"generator_name\": \"exllamav2-mistral7b\",\n",
    "    \"engine\": \"gai.ttt.server.GaiExLlamaV2\",\n",
    "    \"model_path\": \"models/exllamav2-mistral7b\",\n",
    "    \"model_basename\": \"model\",\n",
    "    \"max_seq_len\": 8192,\n",
    "    \"prompt_format\": \"mistral\",\n",
    "    \"hyperparameters\": {\n",
    "        \"temperature\": 0.85,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 50,\n",
    "        \"max_new_tokens\": 1000,\n",
    "    },\n",
    "    \"tool_choice\": \"auto\",\n",
    "    \"max_retries\": 5,\n",
    "    \"stop_conditions\": [\"<s>\", \"</s>\", \"user:\",\"\\n\\n\"],\n",
    "    \"no_flash_attn\":True,\n",
    "    \"seed\": None,\n",
    "    \"decode_special_tokens\": False,\n",
    "    \"module_name\": \"gai.ttt.server.gai_exllamav2\",\n",
    "    \"class_name\": \"GaiExLlamav2\",\n",
    "    \"init_args\": [],\n",
    "    \"init_kwargs\": {}\n",
    "}\n",
    "\n",
    "# before loading\n",
    "free_mem()\n",
    "try:\n",
    "    with SingletonHost.GetInstanceFromConfig(config) as host:\n",
    "\n",
    "        # after loading\n",
    "        free_mem()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    # after disposal\n",
    "    free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Integration Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">1.25</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;91m1.25\u001b[0m\u001b[91m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.2538566589355469"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host = SingletonHost.GetInstanceFromConfig(config, verbose=False)\n",
    "host.load()\n",
    "generator = host.generator\n",
    "free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Test streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a small village nestled between the mountains, lived a kind-hearted young woman named Maya. She was known for her exceptional skill in weaving intricate designs on cloth. One day, a mysterious stranger arrived in the village, seeking her help to weave a magical cloth that could heal the sick. Despite the challenges and threats from those who wished to claim the cloth for their own gain, Maya completed the cloth with courage and perseverance. In the end, the cloth healed the sick, and the stranger, who was actually a guardian angel, rewarded Maya by granting her a wish. Maya wished for the villagers' happiness and prosperity, and from that day forward, the village flourished like never before."
     ]
    }
   ],
   "source": [
    "response = host.generator.create(\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"},\n",
    "                {\"role\":\"assistant\",\"content\":\"\"}],\n",
    "    stream=True)\n",
    "for message in response:\n",
    "    if message.choices[0].delta.content:\n",
    "        print(message.choices[0].delta.content, end=\"\", flush=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a small village nestled between the mountains, lived a kind-hearted and hardworking farmer named Tomas. Despite the harsh conditions, he worked tirelessly to tend to his crops and livestock. One day, a severe storm swept through the valley, destroying Tomas's home and crops. Devastated but not defeated, Tomas rallied the village together, and they rebuilt his home and replanted his fields. The villagers' unwavering support and Tomas's resilient spirit proved that even in the face of adversity, community and determination can help overcome the toughest challenges.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = host.generator.create(\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"},\n",
    "                {\"role\":\"assistant\",\"content\":\"\"}],\n",
    "    stream=False)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Test Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-109a250e-feb0-430a-a39b-946a109cebe9', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_c80da37d-8a6a-48f5-a6e1-2752915e2a12', function=Function(arguments='{\"search_query\": \"current time Singapore\"}', name='google'), type='function')]))], created=1723846895, model='exllamav2-mistral7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=21, prompt_tokens=336, total_tokens=357))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"What is the current time in Singapore?\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"\"}\n",
    "]\n",
    "tool_choice=\"required\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"google\",\n",
    "            \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "response = host.generator.create(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice,\n",
    "    stream=False)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Test Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-7966bf89-fef5-40c9-add3-2460fb6383cc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' {\\n  \"title\": \"Foundation\",\\n  \"summary\": \"Foundation is a science fiction novel by Isaac Asimov, the first published in his Foundation Trilogy. It is a cycle of five interrelated short stories that tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\",\\n  \"author\": \"Isaac Asimov\",\\n  \"published_year\": 1951\\n}', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1723846902, model='exllamav2-mistral7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=116, prompt_tokens=257, total_tokens=373))\n"
     ]
    }
   ],
   "source": [
    "# Define Schema\n",
    "from pydantic import BaseModel\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "text = \"\"\"Foundation is a science fiction novel by American writer\n",
    "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "expanded into the Foundation series). Foundation is a cycle of five\n",
    "interrelated short stories, first published as a single book by Gnome Press\n",
    "in 1951. Collectively they tell the early story of the Foundation,\n",
    "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "of galactic civilization after the collapse of the Galactic Empire.\n",
    "\"\"\"\n",
    "response = host.generator.create(messages=[{'role':'user','content':text},{'role':'assistant','content':''}], \n",
    "    json_schema=Book.schema(),\n",
    "    stream=False\n",
    "    )\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">5.72</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;92m5.72\u001b[0m\u001b[92m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.717174530029297"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del host.generator.model\n",
    "del host.generator.cache\n",
    "del host.generator.tokenizer\n",
    "del host.generator\n",
    "import gc,torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. API Test\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "a) Press `F5` to start the API server.\n",
    "\n",
    "**Tests**:\n",
    "\n",
    "Run the following cells to test the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Test Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-d3d326fa-6258-4780-82d7-ba8e7097a9ae\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\" Once upon a time, in a land far, far away, there was a brave princess named Elara. She lived in a beautiful castle surrounded by a vast forest. One day, a wicked sorcerer cast a spell on the princess, causing her to fall into a deep sleep\",\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}}],\"created\":1723876370,\"model\":\"exllamav2-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":61,\"prompt_tokens\":14,\"total_tokens\":75}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"Tell me a story.\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"tool_choice\\\": \\\"none\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Test Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a small village nestled between the mountains, lived a humble blacksmith named Tomas. He was known for his exceptional skills and was loved by all. One day, a dragon invaded the village, causing chaos and fear. Tomas, despite his fear, decided to confront the dragon. With courage in his heart and a plan in his mind, he crafted a magical sword from the heart of a fallen star. Armed with the sword, Tomas bravely faced the dragon, and with a swift strike, he defeated it, saving his village. Tomas was hailed as a hero, and his bravery and skill became legendary"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import httpx\n",
    "\n",
    "# Generate the JSON payload\n",
    "json_payload = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"stream\": \"true\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a one paragraph story.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send the POST request using httpx with streaming\n",
    "with httpx.Client() as client:\n",
    "    response = client.post(\"http://localhost:12031/gen/v1/chat/completions\", json=json_payload)\n",
    "    for line in response.iter_lines():\n",
    "        result = json.loads(line)\n",
    "        content = result[\"choices\"][0][\"delta\"][\"content\"]\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Test Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-e4556dc3-99f6-4ea9-b802-07f77172a63e\",\"choices\":[{\"finish_reason\":\"tool_calls\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":null,\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":[{\"id\":\"call_0285867a-75b6-4e7d-ba0f-ec3d4bfa8121\",\"function\":{\"arguments\":\"{\\\"search_query\\\": \\\"current time Singapore\\\"}\",\"name\":\"google\"},\"type\":\"function\"}]}}],\"created\":1723876558,\"model\":\"exllamav2-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":21,\"prompt_tokens\":335,\"total_tokens\":356}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"What is the current time in Singapore\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"tools\\\": [\\\n",
    "            {\\\n",
    "                \\\"type\\\": \\\"function\\\",\\\n",
    "                \\\"function\\\": {\\\n",
    "                    \\\"name\\\": \\\"google\\\",\\\n",
    "                    \\\"description\\\": \\\"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\\\",\\\n",
    "                    \\\"parameters\\\": {\\\n",
    "                        \\\"type\\\": \\\"object\\\",\\\n",
    "                        \\\"properties\\\": {\\\n",
    "                            \\\"search_query\\\": {\\\n",
    "                                \\\"type\\\": \\\"string\\\",\\\n",
    "                                \\\"description\\\": \\\"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\\\"\\\n",
    "                            }\\\n",
    "                        },\\\n",
    "                        \\\"required\\\": [\\\"search_query\\\"]\\\n",
    "                    }\\\n",
    "                }\\\n",
    "            }\\\n",
    "        ],\\\n",
    "        \\\"tool_choice\\\": \\\"required\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Test JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-2d3beee6-7121-4a1c-870e-53adaff0ca87\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\" {\\n  \\\"title\\\": \\\"Foundation\\\",\\n  \\\"summary\\\": \\\"Foundation is a science fiction novel by Isaac Asimov, the first published in his Foundation Trilogy. It is a cycle of five interrelated short stories that tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\\\",\\n  \\\"author\\\": \\\"Isaac Asimov\\\",\\n  \\\"published_year\\\": 1951\\n}\",\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}}],\"created\":1723876570,\"model\":\"exllamav2-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":116,\"prompt_tokens\":253,\"total_tokens\":369}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"Foundation is a science fiction novel by American writer \\\n",
    "            Isaac Asimov. It is the first published in his Foundation Trilogy (later \\\n",
    "            expanded into the Foundation series). Foundation is a cycle of five \\\n",
    "            interrelated short stories, first published as a single book by Gnome Press \\\n",
    "            in 1951. Collectively they tell the early story of the Foundation, \\\n",
    "            an institute founded by psychohistorian Hari Seldon to preserve the best \\\n",
    "            of galactic civilization after the collapse of the Galactic Empire.\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"json_schema\\\": {\\\"properties\\\": \\\n",
    "            {\\\"title\\\": \\\n",
    "                {\\\"title\\\": \\\"Title\\\", \\\"type\\\": \\\"string\\\"}, \\\n",
    "                    \\\"summary\\\": {\\\"title\\\": \\\"Summary\\\", \\\"type\\\": \\\"string\\\"}, \\\n",
    "                    \\\"author\\\": {\\\"title\\\": \\\"Author\\\", \\\n",
    "                    \\\"type\\\": \\\"string\\\"\\\n",
    "                }, \\\n",
    "                \\\"published_year\\\": {\\\n",
    "                    \\\"title\\\": \\\"Published Year\\\", \\\n",
    "                    \\\"type\\\": \\\"integer\\\"}}, \\\n",
    "                \\\"required\\\": [\\\n",
    "                    \\\"title\\\", \\\n",
    "                    \\\"summary\\\", \\\n",
    "                    \\\"author\\\", \\\n",
    "                    \\\"published_year\\\"\\\n",
    "                ], \\\n",
    "                \\\"title\\\": \\\"Book\\\", \\\n",
    "                \\\"type\\\": \\\"object\\\"\\\n",
    "            },\\\n",
    "        \\\"tool_choice\\\": \\\"none\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Shut down the API Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Docker\n",
    "\n",
    "This test should **NOT** be run in devcontainer.\n",
    "\n",
    "**Instructions:** \n",
    "\n",
    "- Click on bottom left blue button and select **Reopen Folder in WSL**\n",
    "\n",
    "- Create and activate conda environment\n",
    "\n",
    "    ```bash\n",
    "    conda env create -f environment.yml\n",
    "    conda activate gai-sdk\n",
    "    ```\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Python: Select Interpreter**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **Docker: build**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **Docker: run**\n",
    "\n",
    "**Tests:**\n",
    "\n",
    "Repeat the API test (#)\n",
    "\n",
    "**Tear Down:**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **Docker: stop**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-ttt-svr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
