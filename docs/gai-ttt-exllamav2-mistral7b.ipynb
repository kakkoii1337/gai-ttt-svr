{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Text LLM Server\n",
    "\n",
    "This repository is designed to be used with Visual Studio Code and Docker DevContainer.\n",
    "\n",
    "![dev-container](../img/dev-container.png)\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "a) Download model\n",
    "\n",
    "```bash\n",
    "huggingface-cli download bartowski/Mistral-7B-Instruct-v0.3-exl2 \\\n",
    "    --local-dir ~/.gai/models/exllamav2-mistral7b \\\n",
    "    --local-dir-use-symlinks False\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Smoke Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">5.84</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;92m5.84\u001b[0m\u001b[92m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Performance load_config                      </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 4.82 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 4.82 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">     21.49 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     21.49 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       5.90 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.00 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      5.89 GB </span>│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Performance load_config                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mChange Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m4.82 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m4.82 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m    21.49 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    21.49 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      5.90 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.00 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     5.89 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Performance load_model                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0.01 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 0.01 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.22 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.22 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       5.89 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.00 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      5.89 GB </span>│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Performance load_model                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mChange Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0.01 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m0.01 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.22 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.22 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      5.89 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.00 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     5.89 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                       Performance load_cache                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">   Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 23.19 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 23.19 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      24.28 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      24.28 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       5.89 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">       4.62 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       1.27 GB </span>│\n",
       "└───────────────────┴───────────────┴───────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                       Performance load_cache                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Change Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m  Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m23.19 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m23.19 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     24.28 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     24.28 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      5.89 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m      4.62 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      1.27 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴───────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                    Performance load_tokenizer                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Metric            </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Initial Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Change Value </span>┃<span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  Final Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Function Duration </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             - </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 2.74 seconds </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 2.74 seconds </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CPU Memory        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          - MB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">     49.61 MB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     49.61 MB </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CUDA Memory       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       1.27 GB </span>│<span style=\"color: #808000; text-decoration-color: #808000\">      0.00 GB </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      1.27 GB </span>│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                    Performance load_tokenizer                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mMetric           \u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mInitial Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129mChange Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\u001b[1;38;5;129m \u001b[0m\u001b[1;38;5;129m Final Value\u001b[0m\u001b[1;38;5;129m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mFunction Duration\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            -\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m2.74 seconds\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m2.74 seconds\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCPU Memory       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         - MB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m    49.61 MB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    49.61 MB\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCUDA Memory      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      1.27 GB\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m     0.00 GB\u001b[0m\u001b[33m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     1.27 GB\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────┴───────────────┴──────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">1.27</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;91m1.27\u001b[0m\u001b[91m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">5.77</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;92m5.77\u001b[0m\u001b[92m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gai.lib.server.singleton_host import SingletonHost\n",
    "from gai.lib.common.utils import free_mem\n",
    "from rich.console import Console\n",
    "console=Console()\n",
    "\n",
    "config = {\n",
    "    \"type\": \"ttt\",\n",
    "    \"generator_name\": \"exllamav2-mistral7b\",\n",
    "    \"engine\": \"gai.ttt.server.GaiExLlamaV2\",\n",
    "    \"model_path\": \"models/exllamav2-mistral7b\",\n",
    "    \"model_basename\": \"model\",\n",
    "    \"max_seq_len\": 8192,\n",
    "    \"prompt_format\": \"mistral\",\n",
    "    \"hyperparameters\": {\n",
    "        \"temperature\": 0.85,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 50,\n",
    "        \"max_new_tokens\": 1000,\n",
    "    },\n",
    "    \"tool_choice\": \"auto\",\n",
    "    \"max_retries\": 5,\n",
    "    \"stop_conditions\": [\"<s>\", \"</s>\", \"user:\",\"\\n\\n\"],\n",
    "    \"no_flash_attn\":True,\n",
    "    \"seed\": None,\n",
    "    \"decode_special_tokens\": False,\n",
    "    \"module_name\": \"gai.ttt.server.gai_exllamav2\",\n",
    "    \"class_name\": \"GaiExLlamav2\",\n",
    "    \"init_args\": [],\n",
    "    \"init_kwargs\": {}\n",
    "}\n",
    "\n",
    "# before loading\n",
    "free_mem()\n",
    "try:\n",
    "    with SingletonHost.GetInstanceFromConfig(config) as host:\n",
    "\n",
    "        # after loading\n",
    "        free_mem()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    # after disposal\n",
    "    free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Integration Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">1.24</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;91m1.24\u001b[0m\u001b[91m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.2447967529296875"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host = SingletonHost.GetInstanceFromConfig(config, verbose=False)\n",
    "host.load()\n",
    "generator = host.generator\n",
    "free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Test streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a small village nestled between the mountains, lived a kind-hearted and hardworking farmer named Tomas. Despite the harsh conditions, he worked tirelessly to sustain his family and help his neighbors. One day, a great storm swept through the valley, destroying Tomas's crops and leaving him with nothing. However, the villagers rallied together, sharing their own resources to help Tomas rebuild. The storm may have taken his crops, but it couldn't break the spirit of the community that stood by him.\n"
     ]
    }
   ],
   "source": [
    "response = host.generator.create(\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"},\n",
    "                {\"role\":\"assistant\",\"content\":\"\"}],\n",
    "    stream=True)\n",
    "for message in response:\n",
    "    if message.choices[0].delta.content:\n",
    "        print(message.choices[0].delta.content, end=\"\", flush=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a small village nestled between the mountains, lived a kind-hearted and resourceful young woman named Mia. She was known for her healing herbs and warm smile. One day, a traveling merchant lost his way in a storm and sought shelter in Mia's humble abode. Grateful for her hospitality, he left behind a magical gem, which granted Mia the power to heal any ailment. This gem transformed her into a renowned healer, and the villagers lived in peace and prosperity, thanks to Mia's selfless actions and the magical gem's power.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = host.generator.create(\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"},\n",
    "                {\"role\":\"assistant\",\"content\":\"\"}],\n",
    "    stream=False)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Test Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-b58099e8-b79c-466d-9956-aafb3242b648', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fc9d1739-2842-43d0-983b-8e07961dd8fc', function=Function(arguments='{\"search_query\": \"current time Singapore\"}', name='google'), type='function')]))], created=1723901723, model='exllamav2-mistral7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=21, prompt_tokens=336, total_tokens=357))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"What is the current time in Singapore?\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"\"}\n",
    "]\n",
    "tool_choice=\"required\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"google\",\n",
    "            \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "response = host.generator.create(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice,\n",
    "    stream=False)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Test Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-536f4c2b-b4aa-4a19-a20b-6477bf652d7f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=' {\\n  \"title\": \"Foundation\",\\n  \"summary\": \"Foundation is a science fiction novel by Isaac Asimov, the first published in his Foundation Trilogy. It is a cycle of five interrelated short stories that tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\",\\n  \"author\": \"Isaac Asimov\",\\n  \"published_year\": 1951\\n}', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1723901730, model='exllamav2-mistral7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=116, prompt_tokens=257, total_tokens=373))\n"
     ]
    }
   ],
   "source": [
    "# Define Schema\n",
    "from pydantic import BaseModel\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "text = \"\"\"Foundation is a science fiction novel by American writer\n",
    "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "expanded into the Foundation series). Foundation is a cycle of five\n",
    "interrelated short stories, first published as a single book by Gnome Press\n",
    "in 1951. Collectively they tell the early story of the Foundation,\n",
    "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "of galactic civilization after the collapse of the Galactic Empire.\n",
    "\"\"\"\n",
    "response = host.generator.create(messages=[{'role':'user','content':text},{'role':'assistant','content':''}], \n",
    "    json_schema=Book.schema(),\n",
    "    stream=False\n",
    "    )\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">1.42</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;91m1.42\u001b[0m\u001b[91m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.4186210632324219"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del host.generator.model\n",
    "del host.generator.cache\n",
    "del host.generator.tokenizer\n",
    "del host.generator\n",
    "import gc,torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. API Test\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "a) Press `F5` to start the API server.\n",
    "\n",
    "**Tests**:\n",
    "\n",
    "Run the following cells to test the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Test Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-db8f26e5-fa40-496d-a1e6-86eda2590a26\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\" Once upon a time, in a land far, far away, there was a magical kingdom named Eldoria. The kingdom was known for its beautiful landscapes, friendly inhabitants, and the mysterious Crystal of Life that granted the Eldorians immortality\",\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}}],\"created\":1724227991,\"model\":\"exllamav2-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":54,\"prompt_tokens\":14,\"total_tokens\":68}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"Tell me a story.\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"tool_choice\\\": \\\"none\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Test Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a small village nestled between the mountains, lived a humble blacksmith named Tomas. He was known for his exceptional skills and was loved by all. One day, a dragon invaded the village, causing chaos and fear. Tomas, despite his fear, decided to confront the dragon. With courage in his heart and a plan in his mind, he crafted a magical sword from the heart of a fallen star. Armed with the sword, Tomas bravely faced the dragon, and with a swift strike, he defeated it, saving his village. Tomas was hailed as a hero, and his bravery and skill became legendary"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import httpx\n",
    "\n",
    "# Generate the JSON payload\n",
    "json_payload = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"stream\": \"true\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a one paragraph story.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send the POST request using httpx with streaming\n",
    "with httpx.Client() as client:\n",
    "    response = client.post(\"http://localhost:12031/gen/v1/chat/completions\", json=json_payload)\n",
    "    for line in response.iter_lines():\n",
    "        result = json.loads(line)\n",
    "        content = result[\"choices\"][0][\"delta\"][\"content\"]\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Test Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-e4556dc3-99f6-4ea9-b802-07f77172a63e\",\"choices\":[{\"finish_reason\":\"tool_calls\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":null,\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":[{\"id\":\"call_0285867a-75b6-4e7d-ba0f-ec3d4bfa8121\",\"function\":{\"arguments\":\"{\\\"search_query\\\": \\\"current time Singapore\\\"}\",\"name\":\"google\"},\"type\":\"function\"}]}}],\"created\":1723876558,\"model\":\"exllamav2-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":21,\"prompt_tokens\":335,\"total_tokens\":356}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"What is the current time in Singapore\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"tools\\\": [\\\n",
    "            {\\\n",
    "                \\\"type\\\": \\\"function\\\",\\\n",
    "                \\\"function\\\": {\\\n",
    "                    \\\"name\\\": \\\"google\\\",\\\n",
    "                    \\\"description\\\": \\\"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\\\",\\\n",
    "                    \\\"parameters\\\": {\\\n",
    "                        \\\"type\\\": \\\"object\\\",\\\n",
    "                        \\\"properties\\\": {\\\n",
    "                            \\\"search_query\\\": {\\\n",
    "                                \\\"type\\\": \\\"string\\\",\\\n",
    "                                \\\"description\\\": \\\"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\\\"\\\n",
    "                            }\\\n",
    "                        },\\\n",
    "                        \\\"required\\\": [\\\"search_query\\\"]\\\n",
    "                    }\\\n",
    "                }\\\n",
    "            }\\\n",
    "        ],\\\n",
    "        \\\"tool_choice\\\": \\\"required\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Test JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-8fff830c-45de-4e00-bca1-72289622ed2b\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\" {\\n  \\\"title\\\": \\\"Foundation\\\",\\n  \\\"summary\\\": \\\"Foundation is a science fiction novel by Isaac Asimov, the first published in his Foundation Trilogy. It is a cycle of five interrelated short stories that tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\\\",\\n  \\\"author\\\": \\\"Isaac Asimov\\\",\\n  \\\"published_year\\\": 1951\\n}\",\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}}],\"created\":1724208911,\"model\":\"exllamav2-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":116,\"prompt_tokens\":253,\"total_tokens\":369}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"Foundation is a science fiction novel by American writer \\\n",
    "            Isaac Asimov. It is the first published in his Foundation Trilogy (later \\\n",
    "            expanded into the Foundation series). Foundation is a cycle of five \\\n",
    "            interrelated short stories, first published as a single book by Gnome Press \\\n",
    "            in 1951. Collectively they tell the early story of the Foundation, \\\n",
    "            an institute founded by psychohistorian Hari Seldon to preserve the best \\\n",
    "            of galactic civilization after the collapse of the Galactic Empire.\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"json_schema\\\": {\\\"properties\\\": \\\n",
    "            {\\\"title\\\": \\\n",
    "                {\\\"title\\\": \\\"Title\\\", \\\"type\\\": \\\"string\\\"}, \\\n",
    "                    \\\"summary\\\": {\\\"title\\\": \\\"Summary\\\", \\\"type\\\": \\\"string\\\"}, \\\n",
    "                    \\\"author\\\": {\\\"title\\\": \\\"Author\\\", \\\n",
    "                    \\\"type\\\": \\\"string\\\"\\\n",
    "                }, \\\n",
    "                \\\"published_year\\\": {\\\n",
    "                    \\\"title\\\": \\\"Published Year\\\", \\\n",
    "                    \\\"type\\\": \\\"integer\\\"}}, \\\n",
    "                \\\"required\\\": [\\\n",
    "                    \\\"title\\\", \\\n",
    "                    \\\"summary\\\", \\\n",
    "                    \\\"author\\\", \\\n",
    "                    \\\"published_year\\\"\\\n",
    "                ], \\\n",
    "                \\\"title\\\": \\\"Book\\\", \\\n",
    "                \\\"type\\\": \\\"object\\\"\\\n",
    "            },\\\n",
    "        \\\"tool_choice\\\": \\\"none\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Shut down the API Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Docker\n",
    "\n",
    "This test should **NOT** be run in devcontainer.\n",
    "\n",
    "**Instructions:** \n",
    "\n",
    "- Click on bottom left blue button and select **Reopen Folder in WSL**\n",
    "\n",
    "- Create and activate conda environment\n",
    "\n",
    "    ```bash\n",
    "    conda env create -f environment.yml\n",
    "    conda activate gai-ttt\n",
    "    ```\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Python: Select Interpreter**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **Docker: build**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **Docker: run**\n",
    "\n",
    "**Tests:**\n",
    "\n",
    "Repeat the API test (#)\n",
    "\n",
    "**Tear Down:**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **Docker: stop**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-ttt-svr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
