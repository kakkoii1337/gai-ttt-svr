{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Text LLM Server\n",
    "\n",
    "**important: Select venv Python Interpreter before you start**\n",
    "\n",
    "This repository is designed to be used with Visual Studio Code and Docker DevContainer.\n",
    "\n",
    "![dev-container](../img/dev-container.png)\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "a) Download model\n",
    "\n",
    "```bash\n",
    "huggingface-cli download bartowski/Mistral-7B-Instruct-v0.3-GGUF \\\n",
    "    Mistral-7B-Instruct-v0.3-Q4_K_M.gguf \\\n",
    "    --revision 61fd4167fff3ab01ee1cfe0da183fa27a944db48 \\\n",
    "    --local-dir ~/.gai/models/llamacpp-mistral7b \\\n",
    "    --local-dir-use-symlinks False\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Smoke Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"app_dir\":\"/home/kakkoii1337/.gai\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check .gairc\n",
    "import os\n",
    "gairc=None\n",
    "with open(os.path.expanduser(\"~/.gairc\"),\"r\") as f:\n",
    "    gairc = f.read()\n",
    "print(gairc)\n",
    "\n",
    "# check ~/.gairc (if docker created .gairc)\n",
    "import json\n",
    "jsoned=json.loads(gairc)\n",
    "assert os.path.expanduser(jsoned[\"app_dir\"])==\"/home/kakkoii1337/.gai\"\n",
    "\n",
    "# check ~/.gai (if docker created the mount point)\n",
    "assert os.path.exists(os.path.expanduser(\"~/.gai\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm llama_cpp is importable\n",
    "from llama_cpp import Llama, LlamaGrammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "from gai.lib.server.singleton_host import SingletonHost\n",
    "from gai.lib.common.utils import free_mem\n",
    "from rich.console import Console\n",
    "console=Console()\n",
    "\n",
    "config = {\n",
    "    \"type\": \"ttt\",\n",
    "    \"generator_name\": \"llamacpp-mistral7b\",\n",
    "    \"model_filepath\": \"models/llamacpp-mistral7b/Mistral-7B-Instruct-v0.3-Q4_K_M.gguf\",\n",
    "    \"max_seq_len\": 8192,\n",
    "    \"prompt_format\": \"mistral\",\n",
    "    \"hyperparameters\": {\n",
    "        \"temperature\": 1.31,\n",
    "        \"top_p\": 0.14,\n",
    "        \"top_k\": 49,\n",
    "        \"max_new_tokens\": 1000,\n",
    "    },\n",
    "    \"tool_choice\": \"auto\",\n",
    "    \"max_retries\": 5,\n",
    "    \"stop\": [\"<|eot_id|>\"],\n",
    "    \"module_name\": \"gai.ttt.server.gai_llamacpp\",\n",
    "    \"class_name\": \"GaiLlamaCpp\",\n",
    "    \"init_args\": [],\n",
    "    \"init_kwargs\": {}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "## before loading\n",
    "free_mem()\n",
    "try:\n",
    "    with SingletonHost.GetInstanceFromConfig(config) as host:\n",
    "\n",
    "        ## after loading\n",
    "        free_mem()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    ## after disposal\n",
    "    free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Integration Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Free memory: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4.40</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Free memory: \u001b[1;92m4.40\u001b[0m\u001b[92m GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.399696350097656"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.lib.server.singleton_host import SingletonHost\n",
    "host = SingletonHost.GetInstanceFromConfig(config, verbose=False)\n",
    "host.load()\n",
    "generator = host.generator\n",
    "free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Testing streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = host.generator.create(\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"},\n",
    "                {\"role\":\"assistant\",\"content\":\"\"}],\n",
    "    stream=True)\n",
    "for chunk in response:\n",
    "    if chunk:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = host.generator.create(\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Tell me a one paragraph story\"},\n",
    "                {\"role\":\"assistant\",\"content\":\"\"}],\n",
    "    stream=False)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Test Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array ::= [[] space array_6 []] space \n",
      "space ::= space_94 \n",
      "array_2 ::= value array_5 \n",
      "value ::= object | array | string | number | boolean | null \n",
      "array_4 ::= [,] space value \n",
      "array_5 ::= array_4 array_5 | \n",
      "array_6 ::= array_2 | \n",
      "boolean ::= boolean_8 space \n",
      "boolean_8 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] \n",
      "char ::= [^\"\\] | [\\] char_10 \n",
      "char_10 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "decimal-part ::= [0-9] decimal-part_41 \n",
      "decimal-part_12 ::= [0-9] decimal-part_40 \n",
      "decimal-part_13 ::= [0-9] decimal-part_39 \n",
      "decimal-part_14 ::= [0-9] decimal-part_38 \n",
      "decimal-part_15 ::= [0-9] decimal-part_37 \n",
      "decimal-part_16 ::= [0-9] decimal-part_36 \n",
      "decimal-part_17 ::= [0-9] decimal-part_35 \n",
      "decimal-part_18 ::= [0-9] decimal-part_34 \n",
      "decimal-part_19 ::= [0-9] decimal-part_33 \n",
      "decimal-part_20 ::= [0-9] decimal-part_32 \n",
      "decimal-part_21 ::= [0-9] decimal-part_31 \n",
      "decimal-part_22 ::= [0-9] decimal-part_30 \n",
      "decimal-part_23 ::= [0-9] decimal-part_29 \n",
      "decimal-part_24 ::= [0-9] decimal-part_28 \n",
      "decimal-part_25 ::= [0-9] decimal-part_27 \n",
      "decimal-part_26 ::= [0-9] \n",
      "decimal-part_27 ::= decimal-part_26 | \n",
      "decimal-part_28 ::= decimal-part_25 | \n",
      "decimal-part_29 ::= decimal-part_24 | \n",
      "decimal-part_30 ::= decimal-part_23 | \n",
      "decimal-part_31 ::= decimal-part_22 | \n",
      "decimal-part_32 ::= decimal-part_21 | \n",
      "decimal-part_33 ::= decimal-part_20 | \n",
      "decimal-part_34 ::= decimal-part_19 | \n",
      "decimal-part_35 ::= decimal-part_18 | \n",
      "decimal-part_36 ::= decimal-part_17 | \n",
      "decimal-part_37 ::= decimal-part_16 | \n",
      "decimal-part_38 ::= decimal-part_15 | \n",
      "decimal-part_39 ::= decimal-part_14 | \n",
      "decimal-part_40 ::= decimal-part_13 | \n",
      "decimal-part_41 ::= decimal-part_12 | \n",
      "function ::= [{] space function-name-kv [,] space function-arguments-kv [}] space \n",
      "function-name-kv ::= [\"] [n] [a] [m] [e] [\"] space [:] space string \n",
      "function-arguments-kv ::= [\"] [a] [r] [g] [u] [m] [e] [n] [t] [s] [\"] space [:] space function-arguments \n",
      "function-arguments ::= object \n",
      "object ::= [{] space object_92 [}] space \n",
      "function-kv ::= [\"] [f] [u] [n] [c] [t] [i] [o] [n] [\"] space [:] space function \n",
      "string ::= [\"] string_95 [\"] space \n",
      "integral-part ::= [0-9] | [1-9] integral-part_79 \n",
      "integral-part_50 ::= [0-9] integral-part_78 \n",
      "integral-part_51 ::= [0-9] integral-part_77 \n",
      "integral-part_52 ::= [0-9] integral-part_76 \n",
      "integral-part_53 ::= [0-9] integral-part_75 \n",
      "integral-part_54 ::= [0-9] integral-part_74 \n",
      "integral-part_55 ::= [0-9] integral-part_73 \n",
      "integral-part_56 ::= [0-9] integral-part_72 \n",
      "integral-part_57 ::= [0-9] integral-part_71 \n",
      "integral-part_58 ::= [0-9] integral-part_70 \n",
      "integral-part_59 ::= [0-9] integral-part_69 \n",
      "integral-part_60 ::= [0-9] integral-part_68 \n",
      "integral-part_61 ::= [0-9] integral-part_67 \n",
      "integral-part_62 ::= [0-9] integral-part_66 \n",
      "integral-part_63 ::= [0-9] integral-part_65 \n",
      "integral-part_64 ::= [0-9] \n",
      "integral-part_65 ::= integral-part_64 | \n",
      "integral-part_66 ::= integral-part_63 | \n",
      "integral-part_67 ::= integral-part_62 | \n",
      "integral-part_68 ::= integral-part_61 | \n",
      "integral-part_69 ::= integral-part_60 | \n",
      "integral-part_70 ::= integral-part_59 | \n",
      "integral-part_71 ::= integral-part_58 | \n",
      "integral-part_72 ::= integral-part_57 | \n",
      "integral-part_73 ::= integral-part_56 | \n",
      "integral-part_74 ::= integral-part_55 | \n",
      "integral-part_75 ::= integral-part_54 | \n",
      "integral-part_76 ::= integral-part_53 | \n",
      "integral-part_77 ::= integral-part_52 | \n",
      "integral-part_78 ::= integral-part_51 | \n",
      "integral-part_79 ::= integral-part_50 | \n",
      "null ::= [n] [u] [l] [l] space \n",
      "number ::= number_82 number_85 number_88 space \n",
      "number_82 ::= number_83 integral-part \n",
      "number_83 ::= [-] | \n",
      "number_84 ::= [.] decimal-part \n",
      "number_85 ::= number_84 | \n",
      "number_86 ::= [eE] number_87 integral-part \n",
      "number_87 ::= [-+] | \n",
      "number_88 ::= number_86 | \n",
      "object_89 ::= string [:] space value object_91 \n",
      "object_90 ::= [,] space string [:] space value \n",
      "object_91 ::= object_90 object_91 | \n",
      "object_92 ::= object_89 | \n",
      "root ::= [{] space function-kv [}] space \n",
      "space_94 ::= [ ] | \n",
      "string_95 ::= char string_95 | \n",
      "ChatCompletion(id='chatcmpl-a96a8794-7342-4f48-9fc1-cda961ba201e', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_66e82cc5-dd4f-43ff-9543-3e34e5f43aff', function=Function(arguments='{\"location\": \"Singapore\"}', name='ask_time'), type='function')]))], created=1725102376, model='llamacpp-mistral7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=27, prompt_tokens=16, total_tokens=43))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"What is the current time in Singapore?\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"\"}\n",
    "]\n",
    "tool_choice=\"required\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"google\",\n",
    "            \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "response = host.generator.create(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice,\n",
    "    stream=False)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Test Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author-kv ::= [\"] [a] [u] [t] [h] [o] [r] [\"] space [:] space string \n",
      "space ::= space_43 \n",
      "string ::= [\"] string_44 [\"] space \n",
      "char ::= [^\"\\] | [\\] char_4 \n",
      "char_4 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "integer ::= integer_6 space \n",
      "integer_6 ::= integer_7 integral-part \n",
      "integer_7 ::= [-] | \n",
      "integral-part ::= [0-9] | [1-9] integral-part_38 \n",
      "integral-part_9 ::= [0-9] integral-part_37 \n",
      "integral-part_10 ::= [0-9] integral-part_36 \n",
      "integral-part_11 ::= [0-9] integral-part_35 \n",
      "integral-part_12 ::= [0-9] integral-part_34 \n",
      "integral-part_13 ::= [0-9] integral-part_33 \n",
      "integral-part_14 ::= [0-9] integral-part_32 \n",
      "integral-part_15 ::= [0-9] integral-part_31 \n",
      "integral-part_16 ::= [0-9] integral-part_30 \n",
      "integral-part_17 ::= [0-9] integral-part_29 \n",
      "integral-part_18 ::= [0-9] integral-part_28 \n",
      "integral-part_19 ::= [0-9] integral-part_27 \n",
      "integral-part_20 ::= [0-9] integral-part_26 \n",
      "integral-part_21 ::= [0-9] integral-part_25 \n",
      "integral-part_22 ::= [0-9] integral-part_24 \n",
      "integral-part_23 ::= [0-9] \n",
      "integral-part_24 ::= integral-part_23 | \n",
      "integral-part_25 ::= integral-part_22 | \n",
      "integral-part_26 ::= integral-part_21 | \n",
      "integral-part_27 ::= integral-part_20 | \n",
      "integral-part_28 ::= integral-part_19 | \n",
      "integral-part_29 ::= integral-part_18 | \n",
      "integral-part_30 ::= integral-part_17 | \n",
      "integral-part_31 ::= integral-part_16 | \n",
      "integral-part_32 ::= integral-part_15 | \n",
      "integral-part_33 ::= integral-part_14 | \n",
      "integral-part_34 ::= integral-part_13 | \n",
      "integral-part_35 ::= integral-part_12 | \n",
      "integral-part_36 ::= integral-part_11 | \n",
      "integral-part_37 ::= integral-part_10 | \n",
      "integral-part_38 ::= integral-part_9 | \n",
      "published-year-kv ::= [\"] [p] [u] [b] [l] [i] [s] [h] [e] [d] [_] [y] [e] [a] [r] [\"] space [:] space integer \n",
      "root ::= [{] space title-kv [,] space summary-kv [,] space author-kv [,] space published-year-kv [}] space \n",
      "title-kv ::= [\"] [t] [i] [t] [l] [e] [\"] space [:] space string \n",
      "summary-kv ::= [\"] [s] [u] [m] [m] [a] [r] [y] [\"] space [:] space string \n",
      "space_43 ::= [ ] | \n",
      "string_44 ::= char string_44 | \n",
      "ChatCompletion(id='chatcmpl-e11b65c4-9f58-465f-b356-26285855c940', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{ \"title\": \"Foundation\", \"summary\": \"Foundation is a science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series). Foundation is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. Collectively they tell the early story of the Foundation, an institute founded by psychohistorian Hari Seld', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725102419, model='llamacpp-mistral7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=124, total_tokens=224))\n"
     ]
    }
   ],
   "source": [
    "# Define Schema\n",
    "from pydantic import BaseModel\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "text = \"\"\"Foundation is a science fiction novel by American writer\n",
    "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "expanded into the Foundation series). Foundation is a cycle of five\n",
    "interrelated short stories, first published as a single book by Gnome Press\n",
    "in 1951. Collectively they tell the early story of the Foundation,\n",
    "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "of galactic civilization after the collapse of the Galactic Empire.\n",
    "\"\"\"\n",
    "response = host.generator.create(messages=[{'role':'user','content':text},{'role':'assistant','content':''}], \n",
    "    json_schema=Book.schema(),\n",
    "    stream=False\n",
    "    )\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. API Test\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "a) Press `F5` to start the API server.\n",
    "\n",
    "b) Wait for the server to start.\n",
    "\n",
    "**Tests**:\n",
    "\n",
    "Run the following cells to test the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Test Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-8bfa4eb5-3bee-4095-bc7f-0edda3e02984\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\" Once upon a time, in a land far, far away, there was a small village nestled between towering mountains and a vast, sparkling lake. The village was known for its beautiful gardens, filled with vibrant flowers and lush greenery. The villagers were hardworking and kind, and they lived in harmony with nature.\\n\\nOne day, a mysterious stranger arrived in the village. He was tall and lean, with piercing blue eyes and a long, flowing beard. He carried a large pack on his back and wore a cloak that seemed to change colors depending on the light. The villagers were wary of him at first, but he seemed peaceful and harmless, so they allowed him to stay.\\n\\nThe stranger settled into a small cottage on the outskirts of the village, and he spent his days wandering the gardens and talking to the villagers. He was a skilled gardener, and he offered to help the villagers tend to their crops and flowers. The villagers were grateful for his help, and they soon grew to trust and like him.\\n\\nAs the days passed, the stranger began to reveal his true nature. He was a powerful sorcerer, and he had come to the village to learn the secrets of its magical gardens. The villagers were shocked and frightened, but the stranger reassured them that he meant them no harm. He promised to use his powers for good, and to help the village prosper.\\n\\nThe villagers were still hesitant, but they couldn't deny the benefits of the stranger's magic. The gardens grew more beautiful than ever before, and the crops were bountiful. The villagers were happy and prosperous, and they began to see the stranger in a new light.\\n\\nOne day, a great evil threatened the village. A dark sorcerer had risen to power, and he sought to destroy the magical gardens and take control of the village. The villagers were terrified, but the stranger stepped forward to defend them.\\n\\nWith his powerful magic, the stranger battled the dark sorcerer and his minions. The battle was fierce and long, but in the end, the stranger emerged victorious. The dark sorcerer was defeated, and the village was saved.\\n\\nThe villagers were grateful to the stranger for his bravery and his help. They realized that he was not just a sorcerer, but a hero. They offered him a place among them, and he accepted. From that day on, the stranger lived in the village, using his powers to protect and help the people. And the village flourished, thanks to the magic of the gardens and the wisdom of the sorcerer who had become one of its own.\\n\\nThe end.\",\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}}],\"created\":1725272481,\"model\":\"llamacpp-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":574,\"prompt_tokens\":13,\"total_tokens\":587}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"llamacpp-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"Tell me a story.\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"tool_choice\\\": \\\"none\\\"}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Test Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the heart of a bustling city, a young street musician named Ethan played his violin, his melodies weaving through the cacophony of urban life. One day, a stranger approached him, a worn-out suitcase in hand. The stranger, an elderly woman, handed Ethan a tattered envelope containing a symphony score. \"This is a composition by my late husband,\" she said, her eyes filled with tears. \"He always dreamed of hearing it performed, but never had the chance. I want you to play it.\" Touched by her story, Ethan promised to honor the woman's request, and that night, under the city lights, he played the forgotten symphony, a poignant tribute to a dream deferred. The music, a beautiful blend of sorrow and hope, echoed through the city, touching the hearts of all who heard it."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import httpx\n",
    "\n",
    "# Generate the JSON payload\n",
    "json_payload = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"stream\": \"true\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a one paragraph story.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send the POST request using httpx with streaming\n",
    "with httpx.Client(timeout=30.0) as client:\n",
    "    response = client.post(\"http://localhost:12031/gen/v1/chat/completions\", json=json_payload)\n",
    "    for line in response.iter_lines():\n",
    "        result = json.loads(line)\n",
    "        content = result[\"choices\"][0][\"delta\"][\"content\"]\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Test Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-cc9d6318-d239-4686-926d-6e7049346b0f\",\"choices\":[{\"finish_reason\":\"tool_calls\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":null,\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":[{\"id\":\"call_191e7a67-4fd1-4d9d-a136-f8c153ae8a4c\",\"function\":{\"arguments\":\"{\\\"location\\\": \\\"Singapore\\\"}\",\"name\":\"ask_time\"},\"type\":\"function\"}]}}],\"created\":1725122276,\"model\":\"llamacpp-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":26,\"prompt_tokens\":15,\"total_tokens\":41}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"What is the current time in Singapore\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"tools\\\": [\\\n",
    "            {\\\n",
    "                \\\"type\\\": \\\"function\\\",\\\n",
    "                \\\"function\\\": {\\\n",
    "                    \\\"name\\\": \\\"google\\\",\\\n",
    "                    \\\"description\\\": \\\"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\\\",\\\n",
    "                    \\\"parameters\\\": {\\\n",
    "                        \\\"type\\\": \\\"object\\\",\\\n",
    "                        \\\"properties\\\": {\\\n",
    "                            \\\"search_query\\\": {\\\n",
    "                                \\\"type\\\": \\\"string\\\",\\\n",
    "                                \\\"description\\\": \\\"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\\\"\\\n",
    "                            }\\\n",
    "                        },\\\n",
    "                        \\\"required\\\": [\\\"search_query\\\"]\\\n",
    "                    }\\\n",
    "                }\\\n",
    "            }\\\n",
    "        ],\\\n",
    "        \\\"tool_choice\\\": \\\"required\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Test JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-5184ce5e-8f31-4f6e-aee5-6f2ebd71341d\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"{ \\\"title\\\": \\\"Foundation\\\", \\\"summary\\\": \\\"Foundation is a science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series). Foundation is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. Collectively they tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\\\", \\\"author\\\": \\\"Isaac Asimov\\\", \\\"published_year\\\": 1951}\",\"refusal\":null,\"role\":\"assistant\",\"function_call\":null,\"tool_calls\":null}}],\"created\":1725122322,\"model\":\"llamacpp-mistral7b\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":146,\"prompt_tokens\":120,\"total_tokens\":266}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST \\\n",
    "    http://localhost:12031/gen/v1/chat/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -s \\\n",
    "    -N \\\n",
    "    -d \"{\\\"model\\\":\\\"exllamav2-mistral7b\\\", \\\n",
    "        \\\"messages\\\": [ \\\n",
    "            {\\\"role\\\": \\\"user\\\",\\\"content\\\": \\\"Foundation is a science fiction novel by American writer \\\n",
    "            Isaac Asimov. It is the first published in his Foundation Trilogy (later \\\n",
    "            expanded into the Foundation series). Foundation is a cycle of five \\\n",
    "            interrelated short stories, first published as a single book by Gnome Press \\\n",
    "            in 1951. Collectively they tell the early story of the Foundation, \\\n",
    "            an institute founded by psychohistorian Hari Seldon to preserve the best \\\n",
    "            of galactic civilization after the collapse of the Galactic Empire.\\\"}, \\\n",
    "            {\\\"role\\\": \\\"assistant\\\",\\\"content\\\": \\\"\\\"} \\\n",
    "        ],\\\n",
    "        \\\"json_schema\\\": {\\\"properties\\\": \\\n",
    "            {\\\"title\\\": \\\n",
    "                {\\\"title\\\": \\\"Title\\\", \\\"type\\\": \\\"string\\\"}, \\\n",
    "                    \\\"summary\\\": {\\\"title\\\": \\\"Summary\\\", \\\"type\\\": \\\"string\\\"}, \\\n",
    "                    \\\"author\\\": {\\\"title\\\": \\\"Author\\\", \\\n",
    "                    \\\"type\\\": \\\"string\\\"\\\n",
    "                }, \\\n",
    "                \\\"published_year\\\": {\\\n",
    "                    \\\"title\\\": \\\"Published Year\\\", \\\n",
    "                    \\\"type\\\": \\\"integer\\\"}}, \\\n",
    "                \\\"required\\\": [\\\n",
    "                    \\\"title\\\", \\\n",
    "                    \\\"summary\\\", \\\n",
    "                    \\\"author\\\", \\\n",
    "                    \\\"published_year\\\"\\\n",
    "                ], \\\n",
    "                \\\"title\\\": \\\"Book\\\", \\\n",
    "                \\\"type\\\": \\\"object\\\"\\\n",
    "            },\\\n",
    "        \\\"tool_choice\\\": \\\"none\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Shut down the API Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Docker\n",
    "\n",
    "This test should **NOT** be run in devcontainer.\n",
    "\n",
    "**Instructions:** \n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **docker-compose: up**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoke Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    34  100    34    0     0   1014      0 --:--:-- --:--:-- --:--:--  1030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"gai-ttt-svr-llamacpp\"}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl http://localhost:12031\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests:**\n",
    "\n",
    "Repeat the API test (#)\n",
    "\n",
    "**Tear Down:**\n",
    "\n",
    "- Press **CTRL+SHIFT+P** > **Tasks: Run Task** > **docker-compose: down**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "a) Container must be started with \"python -m debugpy --listen 0.0.0.0:5678 main.py\"\n",
    "\n",
    "b) Port 5678 must be opened.\n",
    "\n",
    "c) Click on \"Debug\" in Tool bar\n",
    "\n",
    "d) Select \"Attach\" > \"Run and Debug\"\n",
    "\n",
    "e) Add a \"breakpoint\" in the code\n",
    "\n",
    "f) Run the API test to see if it trigger the breakpoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
