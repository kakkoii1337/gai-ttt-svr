api_url: ""
logging:
    level: "INFO"
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    datefmt: "%Y-%m-%d %H:%M:%S"
    filename: ""
    filemode: "a"
    stream: "stdout"
    loggers:
        gai.ttt: "DEBUG"
        gai.common.http_utils: "DEBUG"
gen:
    default:
        ttt: "ttt-llamacpp-mistral7b"
    ttt-llamacpp-mistral7b:
        type: "ttt"
        generator_name: "llamacpp-mistral7b"
        model_filepath: "models/llamacpp-mistral7b/Mistral-7B-Instruct-v0.3-Q4_K_M.gguf"
        max_seq_len: 8192
        prompt_format: "mistral"
        hyperparameters:
            {
                "temperature": 1.31,
                "top_p": 0.14,
                "top_k": 49,
                "max_tokens": 1000,
            }
        tool_choice: "auto"
        max_retries: 5
        stop: ["<|eot_id|>"]
        module_name: "gai.ttt.server.gai_llamacpp"
        class_name: "GaiLlamaCpp"
        init_args: []
        init_kwargs: {}

